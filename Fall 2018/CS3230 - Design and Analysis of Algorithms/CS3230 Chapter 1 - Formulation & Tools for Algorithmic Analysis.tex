\documentclass[a4paper]{article}

\input{header}

\title{%
	CS3230 Chapter 1 - Formulation \& Tools for Algorithmic Analysis \\
	\large Based on lectures by Chang Ee-Chien
	\\ Notes taken by Andrew Tan
	\\ AY18/19 Semester 1
	\\ }

\author{}
\date{\vspace{-5ex}}

\begin{document}
\maketitle

\begin{center}\begin{minipage}[c]{0.9\textwidth}\centering\footnotesize These notes are not endorsed by the lecturers, and I have modified them (often significantly) after lectures. They are nowhere near accurate representations of what was actually lectured, and in particular, all errors are almost surely mine.\end{minipage}\end{center}

\section{Algorithms}
An algorithm is a sequence of computational steps that transform a given input into an output.\\ \\Given a problem, an effective algorithm would be both correct and efficient in execution, in that it would compute the correct solution from given input instances, and minimizes the time and space needed for computation.

\section{Asymptotic Notations}
\subsection{Big-O Notation}
Let $f(n)$ and $g(n)$ be functions on $\Z_{+}$. We say that $f(n) \in O(g(n))$ if there exists positive constants $c$ and $n_0$ such that $\forall n > n_0, f(n) \le cg(n)$.
\begin{center} $O(g(n)) = \{f(n): \exists c>0$ and $n_0>0$ such that \\$\forall n>n_0, f(n) \le cg(n)\}$ \end{center}

\subsection{Big-Omega Notation}
Let $f(n)$ and $g(n)$ be functions on $\Z_{+}$. We say that $f(n) \in \Omega(g(n))$ if there exists positive constants $c$ and $n_0$ such that $\forall n > n_0, f(n) \ge cg(n)$.
\begin{center} $\Omega(g(n)) = \{f(n): \exists c>0$ and $n_0>0$ such that \\$\forall n>n_0, f(n) \ge cg(n)\}$ \end{center}

\subsection{Big-Theta Notation}
Let $f(n)$ and $g(n)$ be functions on $\Z_{+}$. We say that $f(n) \in \Theta(g(n))$ if $f(n) \in O(g(n))$ and $f(n) \in \Omega(g(n)) O(f(n))$

\begin{center} $\Theta(f(n)) \equiv O(f(n))\cap \Omega(f(n))$ \end{center}

\subsection{Proving asymptotic bounds}
\textbf{Lemma 1.}\\
Consider the two functions $f(n)$ and $g(n)$ where $\forall n \in \Z$, $f(n) > 0$ and $g(n) > 0$, and
\begin{center} $$\lim_{x\to\infty}f(n)/g(n) = c$$ \end{center}
then,\\
if $c=0$, then $f(n)\in O(g(n)), f(n) \notin \Omega(g(n))$\\
if $c=\infty$, then $f(n)\in \Omega(g(n)), f(n) \notin O(g(n))$\\
if $0<c<\infty$, then $f(n)\in \Theta(g(n))$

\subsection{Elementary operations}
In analysis, we only take the elementary operations into account. Elementary operations can consist of the following:
\begin{itemize}
	\itemsep0em
	\item comparison
	\item assignment
	\item arithmetic
\end{itemize}
When performing analysis, the running time of a given algorithm is calculated from the number of elementary operations taken.

\subsection{Best, worst, and average case}
The time and space required by an algorithm may vary between different instances.
\subsubsection{Worst-case analysis}
The performance of the algorithm based on the worst possible input instance.
\subsubsection{Best-case analysis}
The performance of the algorithm based on the best possible input instance.
\subsubsection{Average-case analysis}
the average performance of the algorithm calculated based on all the possible input instances.

\section{Recurrence Equations}
A recurrence equation defines a function, say T(n), recursively.
It is solved if we express it explicitly.\\
To calculate the time complexity of a recursive function, we can apply the Master Theorem.\\\\
\textbf{Master Theorem}\\
Let $a \ge 1$ and $b>1$ be constants, let $f(n)$ be a function, and let $T(n)$ be defined on the nonnegative integers by the recurrence, 
\[
	T(n)=
	\begin{cases}
		0, & \text{if } n=1\\
		aT(n/b) + f(n), & \text{otherwise}
	\end{cases}
\]
Then,
\begin{enumerate}
	\item If $f(n) \in O(n^{\log_b(a-\epsilon)})$ for some constant $\epsilon > 0$ then $T(n) \in \Theta(n^{\log_b(a)})$
	\item If $f(n) \in \Theta(n^{\log_b(a)})$ for some constant $\epsilon > 0$ then $T(n) \in \Theta(n^{\log_b(a)}\log(n))$
	\item If $f(n) \in \Omega(n^{\log_b(a+\epsilon)})$ for some constant $\epsilon > 0$, and if $af(n/b)\le cf(n)$ for some constant $c<1$ and all sufficiently large $n$, then $T(n) = \Theta(f(n))$
\end{enumerate}

\end{document}