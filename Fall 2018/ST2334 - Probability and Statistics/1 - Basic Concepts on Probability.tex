\documentclass[a4paper]{article}

\input{header}

\title{%
	ST2334 Part 1 - Basic Concepts on Probability  \\
	\large Based on lectures by Chan Yiu Man
	\\ Notes taken by Andrew Tan
	\\ AY18/19 Semester 1
	\\ }

\author{}
\date{\vspace{-5ex}}

\begin{document}
\maketitle

\begin{center}\begin{minipage}[c]{0.9\textwidth}\centering\footnotesize These notes are not endorsed by the lecturers, and I have modified them (often significantly) after lectures. They are nowhere near accurate representations of what was actually lectured, and in particular, all errors are almost surely mine.\end{minipage}\end{center}

\section{Sample space and sample points}
\subsection{Sample space}
An \textbf{observation} refers to any numerical or categorical recording of information.\\
A \textbf{statistical experiment} is a procedure that generates a set of data or observations.\\
The \textbf{sample space} of a statistical experiment is the set of all possible outcomes, and is represented by the symbol $S$.\\
\subsection{Sample points}
Every outcome in a sample space is thus called an element of the sample space or simply a \textbf{sample point}.\\
\section{Events}
An \textbf{event} is a subset of a sample space.
\subsection{Simple and compound events}
A \textbf{Simple event} is an event with exactly one outcome (i.e. one sample point).\\
A \textbf{compound event} is an event that consists of more than one outcomes (or sample points).\\ \\
Note that the sample space is itself an event, and it is called a \textbf{sure event}. Furthermore, a subset of $S$ that contains no elements at all is the empty set, denoted by $\emptyset$, and is called a \textbf{null event}.
\subsection{Operations with events}
\subsubsection{Union and intersection events}
Let $S$ denote a sample space, $A$ and $B$ are any two events of $S$.\\
The \textbf{union} of two events A and B, denoted $A \cup B$, is the event containing all the elements that belong to A or B or to both. That is,
\begin{center}
	$A \cup B = \{x: x \in A$ or $x \in B\}$
\end{center}
Furthermore, the union of $n$ events $A_1, A_2, ..., A_n$, denoted by $A_1 \cup A_2 \cup ... \cup A_n$, is the event containing all the elements that belong to one or more of the events $A_1$, or $A_2$, or ..., or $A_n$. That is,
\begin{center}
	$\bigcup\limits_{i=1}^{n} A_i = A_1 \cup A_2 \cup ... \cup A_n = \{x:x\in A_1$ or $...$ or $x\in A_n\}$
\end{center}
The \textbf{intersection} of two events $A$ and $B$, denoted $A \cap B$ or $AB$, is the event containing elements that are common to both $A$ and $B$. That is,
\begin{center}
	$A \cap B = \{x:x \in A $ and $x \in B\}$
\end{center}
Furthermore, the intersection of $n$ events $A_1, A_2, ..., A_n$, denoted by $A_1 \cap A_2 \cap ... \cap A_n$, is the event containing all the elements that are common to all the events $A_1$, and $A_2$, and ..., and $A_n$. That is,
\begin{center}
	$\bigcap\limits_{i=1}^{n} A_i = A_1 \cap A_2 \cap ... \cap A_n = \{x:x\in A_1$ and $...$ and $x\in A_n\}$
\end{center}
\subsubsection{Complement event}
The \textbf{complement} of an event $A$ with respect to $S$, denoted by $A'$ or $A^\complement$, is the set of all elements of $S$ that are not in $A$. That is,
\begin{center}
	$A' = \{x:x\in S$ and $x \notin A\}$
\end{center}
\subsection{Mutually exclusive events}
Two events $A$ and $B$ are said to be \textbf{mutually exclusive} or \textbf{mutually disjoint} if $A\cap B = \emptyset$. That is, if $A$ and $B$ have no elements in common.
\subsection{De Morgan's Law}
For any $n$ events $A_1, A_2, ..., A_n$,
\begin{enumerate}
	\item $(A_1 \cup A_2 \cup ... \cup A_n)' = A_1' \cap A_2' \cap ... \cap A_n'$
	\item $(A_1 \cap A_2 \cap ... \cap A_n)' = A_1' \cup A_2' \cup ... \cup A_n'$
\end{enumerate}
\subsection{Contained events}
If all of the elements in an event $A$ are also in an event $B$, then event $A$ is \textbf{contained} in event $B$, denoted by
\begin{center}
	$A \subset B$
\end{center}
If $A \subset B$ and $B \subset A$, then $A=B$

\section{Counting Methods}
\subsection{Multiplication principle}
If an operation can be performed in $n_1$ ways, and if for each of these ways a second operation can be performed in $n_2$ ways, and for each of the first two ways, a third operation can be performed in $n_3$ ways, and so forth, then the number of ways the sequence of $k$ operations can be performed is
\begin{center}
	$n_1n_2\dots n_k$
\end{center}
\subsection{Addition principle}
Suppose that a procedure, designated by 1 can be performed in $n_1$ ways, and there was another procedure, designated by 2, can be performed in $n_2$ ways, and so forth, and suppose furthermore that no two procedures may be performed together, then the number of ways in which we can perform $1$ or $2$ or $\dots$ or $k$ is given by
\begin{center}
	$n_1 + n_2 + \dots + n_k$
\end{center}
\subsection{Permutations}
A \textbf{permutation} is an ordered arrangement of $r$ objects from a set of $n$ objects, where $r \le n$.\\ \\
The number of permutations of $n$ distinct objects taken $r$ at a time is denoted by 
\begin{center}
	$\perm{n}{k} = n(n-1)(n-2)\dots (n-(r-1)) = \frac{n!}{(n-r)!}$
\end{center}
Hence, where $r=n$, the number of permutations of n distinct objects taken all together is $n!$.\\
\subsubsection{Circular permutations}
The number of permutations of $n$ distinct objects arranged in a circle is $(n-1)!$
\subsubsection{Permutaions with non-distinct objects}
Suppose we have $n$ objects such that there are $n_1$ of one kind, $n_2$ of a second kind, $\dots$, $n_k$ of a $k^{th}$ kind, where 
\begin{center}
	$n_1+n_2+\dots +n_k = n$
\end{center} 
Then the number of distinct permutations of these $n$ objects taken all together is given by 
\begin{center}
	$\perm{n}{n_1,n_2,\dots,n_k} = \frac{n!}{n_1!n_2!\dots n_k!}$
\end{center}
\subsection{Combination}
A \textbf{combination} is an unordered arrangement  of $r$ objects from a set of $n$ objects, where $r \le n$.\\
A combination creates a partition with 2 groups, one group containing the $r$ objects selected and the other group containing the $n-r$ objects that are left.\\ \\
The number of such combinations is denoted by 
\begin{center}
	$n\choose r$ or $\comb{n}{r}$
\end{center}
and the number of combinations of $n$ distinct objects taken $r$ at a time is
\begin{center}
	${n}\choose{r}$ $= \frac{n!}{r!(n-r)!}$
\end{center}
This can be calculated by observing that there are $r!$ permutations of any $r$ objects we select from a set of $n$ distinct objects, hence
\begin{center}
	$\comb{n}{r} r!$ = $\perm{n}{r}$
\end{center}
\subsection{Binomial coefficient}
The quantity $n\choose r$ is called a \textbf{binomial coefficient} because it is the coefficient of the term $a^rb^{n-r}$ in the binomial expansion of $(a+b)^n$.

\section{Relative frequency annd definition of probability}
The \textbf{relative frequency} of an event is the fraction of the number of occurences of the event over the total number of events.
Let $n_A$ be the number of times that the event $A$ occured among the $n$ repetitions respectively.
Then the relative frequency can be denoted as
\begin{center}
	$f_A = \frac{n_A}{n}$
\end{center}
If $A$ and $B$ are two mutually exclusive events and if $f_{A\cup B}$ is the relative frequency associated with the event $A\cup B$, then $f_{A\cup B} = f_A + f_B$\\
Furthermore, $f_A$ approaches some definite numerical value as the total number of events increase.
\subsection{Axioms of probability}
Consider an experiment whose sample space is $S$. The objective of probability is to assign to each event $A_i$, a number $Pr(A_i)$, called the probabiity of the event $A_i$, which gives a precise measure of the chance that $A_i$ will occur.\\
Consider the collection of all events and denote it $P$. For each event $A$ of the sample space $S$ we assume that a number $Pr(A_i)$, which si called the probability of the event $A$, is defined and satisfies the following three axioms:
\begin{description}
	\item[Axiom 1:] $0 \le Pr(A_i) \le 1$
	\item[Axiom 2:] $Pr(S) = 1$
	\item[Axiom 3:] If $A_1,A_2,\dots$ are mutually exclusive (disjoint) events, then 
	\begin{center}
		$Pr(\bigcup\limits_{i=1}^{\infty}A_i) = \sum\limits_{i=1}^{\infty}Pr(A_i)$
	\end{center}
	in particular, if $A$ and $B$ are two mutually exclusive events, then $Pr(A\cup B) = Pr(A) + Pr(B)$
\end{description}

\section{Conditional probability}
Let $A$ and $B$ be two events associated with an experiment $E$. 
The \textbf{conditional probability} of the event $B$, given that event $A$ has occured is defined as 
\begin{center}
	$Pr(B|A) = \frac{Pr(A\cap B)}{Pr(A)}$,$\tab$ if $Pr(A) \neq 0$
\end{center}
For a fixed $A$, The conditional probability $Pr(B|A)$ still satisfies the various axioms of probability:
\begin{description}
	\item[Axiom 1:] $0 \le Pr(B|A) \le 1$
	\item[Axiom 2:] $Pr(S|A) = 1$
	\item[Axiom 3:] If $B_1,B_2,\dots$ are mutually exclusive (disjoint) events, then 
	\begin{center}
		$Pr(\bigcup\limits_{i=1}^{\infty}B|A_i) = \sum\limits_{i=1}^{\infty}Pr(B_i|A)$
	\end{center}
	in particular, if $B_1$ and $B_2$ are two mutually exclusive events, then \\$Pr(B_1\cup B_2 |A) = Pr(B_1|A) + Pr(B_2|A)$
\end{description}
\subsection{Multiplication rule of probability}
The probability of both events $A$ and  $B$ occuring is the product of the probability of one event occuring and the conditional probability that the other event occurs given that the first event has occured.
\begin{center}
	$Pr(A\cap B) = Pr(A)Pr(B|A)$\\
	$Pr(A\cap B) = Pr(B)Pr(A|B)$   
\end{center}
In general,
\begin{center}
	$Pr(A_1\cap\dots\cap A_n) = Pr(A_1)Pr(A_2|A_1)Pr(A_3|A_1\cap A_2)\dots Pr(A_n|A_1\cap\dots\cap A_{n-1})$
\end{center}
provided that $Pr(A_n|A_1\cap\dots\cap A_{n-1}) > 0$ .
\subsection{The law of total probability}
Let $A_1, A_2, \dots, A_n$ be a \textbf{partition} of the sample space $S$. That is, $A_1, A_2, \dots, A_n$ are mutually exlusive and exhaustive events such that $A_i \cap A_j = \emptyset$ for $i \neq j$ and $\bigcup\limits_{i=1}^{n}A_i = S$\\
Then for any event $B$,
\begin{center}
	$Pr(B) = \sum\limits_{i=1}^{n}Pr(B\cap A_i) = \sum\limits_{i=1}^{n}Pr(A_i)Pr(B|A)$
\end{center}
\subsection{Bayes' Theorem}
Let $A_1, A_2, \dots, A_n$ be a partition of the sample space $S$. Then,
\begin{center}
	$Pr(A_k|B) = \frac{Pr(A_k)Pr(B|A_k)}{\sum_{i=1}^{n}Pr(A_i)Pr(B|A)} = \frac{Pr(A_k)Pr(B|A_k)}{Pr(B)}$
\end{center}
for $k = 1, 2, \dots, n$.

\section{Independent events}
Two events $A$ and $B$ are said to be \textbf{independent} if and only if 
\begin{center}
	$Pr(A\cap B) = Pr(A)Pr(B)$
\end{center}
Two events $A$ and $B$ that are not independent are said to be \textbf{dependent}.
\subsection{Properties of independent events}

Suppose $Pr(A)>0$, $Pr(B)>0$.
\begin{enumerate}
	\item If $A$ and $B$ are independent, then
	\begin{center}
		$Pr(B|A) = Pr(B)$ and $Pr(A|B) = Pr(A)$
	\end{center}
	\item If $A$ and $B$ are independent events, then events $A$ and $B$ cannot be mutually exclusive.
	\item If $A$ and $B$ are mutually excusive, then $A$ and $B$ cannot be independent.
	\item The sample space $S$ as well as the empty set $\emptyset$ are independent of any event.
	\item If $A \subset B$, then $A$ and $B$ are dependent unless $B = S$.
	\item If $A$ and $B$ are independent, then so are $A$ and $B'$, $A'$ and $B$, $A'$ and $B'$.
\end{enumerate}
\subsection{n Independent Events}
\subsubsection{Pairwise independent events}
A set of events $A_1$, $A_2$, $\dots$, $A_n$ are said to be pairwise independent if and only if 
\begin{center}
	$Pr(A_i \cap A_j) = Pr(A_i)Pr(A_j)$
\end{center}
for $i\neq j$ and $i$, $j = 1,\dots,n$
\subsubsection{n Mutually independent events}
The events $A_1$, $A_2$, $\dots$, $A_n$ are called \textbf{mutually independent} if and only if for any subset {$A_{i_1}$, $A_{i_2}$, $\dots$, $A_{i_k}$} of $A_1$, $A_2$, $\dots$, $A_n$,
\begin{center}
	$Pr(A_{i_1} \cap A_{i_2} \cap \dots \cap A_{i_k}) = Pr(A_{i_1})Pr(A_{i_2})\dots Pr(A_{i_k})$
\end{center}
\newpage
\appendix
\section{Basic properties of operations of events}
\begin{enumerate}
	\item $A \cap A' = \emptyset$
	\item $A \cap \emptyset = \emptyset$
	\item $A \cup A' = S$
	\item $(A')' = A$
	\item $(A \cap B)' = A' \cup B'$
	\item $(A \cup B)' = A' \cap B'$
	\item $A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$
	\item $A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$
	\item $A \cup B = A \cup (B \cap A')$
	\item $A = (A \cap B) \cup (A \cap B')$
\end{enumerate}
\section{Basic properties of probability}
\begin{enumerate}
	\item $Pr(\emptyset) = 0$
	\item If $A_1, A_2,\dots,A_n$ are mutually exclusive events, then
	\begin{center}
		$Pr(\bigcup\limits_{i=1}^{n}A_i)=\sum_{i=1}^{n}Pr(A_i)$
	\end{center}
	\item For any event A, $Pr(A') = 1 - Pr(A)$
	\item For any two events $A$ and $B$, 
	\begin{center}
		$Pr(A) = Pr(A\cap B) + Pr(A \cap B')$
	\end{center}
	\item For any two events $A$ and $B$,
	\begin{center}
		$Pr(A \cup B) = Pr(A) + Pr(B) - Pr(A\cap B)$
	\end{center}
	\item \textbf{The Inclusion-Exclusion Principle} - For any $n$ events $A_1$, $A_2$, $\dots$, $A_n$,
	\begin{center}
		$Pr(A_1\cup A_2\cup \dots \cup A_n) = \sum\limits_{i=1}^{n}Pr(A_i) - \sum_{i=1}^{n-1}\sum\limits_{j=i+1}^{n}Pr(A_i\cap A_j) +$\\$\sum\limits_{i=1}^{n-2}\sum\limits_{j=i+1}^{n-1}\sum\limits_{k=j+1}^{n}Pr(A_i\cap A_j\cap A_k) - \dots \dots +(-1)^{n+1}Pr(A_1\cap A_2\cap \dots \cap A_n)$
	\end{center}
	\item If $A \subset B$, then $Pr(A) \le Pr(B)$.
\end{enumerate}
\end{document}